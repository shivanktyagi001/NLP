{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO27OWULzr1uIvTu8gsux2H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivanktyagi001/NLP/blob/main/NLP_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK:::**\n",
        "\n"
      ],
      "metadata": {
        "id": "eoB1130GBstO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "#4 thnings to do with NLTK\n",
        "# a.Tokenization\n",
        "# b.stpword Removal\n",
        "# c Stemming\n",
        "# d.Lemmatization"
      ],
      "metadata": {
        "id": "VbcGpxkFB5gk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZyfk0xBCZop",
        "outputId": "0efaf86a-425b-4c36-d7d8-2fbe892627a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt_tab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bHd-06PEnKZ",
        "outputId": "b134e8d7-f59e-48f3-d80a-ef05b68a153f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokeniazation\n",
        "from nltk.tokenize import  word_tokenize\n",
        "#STopword list\n",
        "from nltk.corpus import stopwords\n",
        "#stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "#lemmatization\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "-TJJcANwDAnt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_txt = \"I am learning python,Programming. Python is greatest language....!!!!!\""
      ],
      "metadata": {
        "id": "3D8yP6KODmqk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step -1:LowerCase\n",
        "raw_txt = raw_txt.lower()\n",
        "print(\"LowerCase: \",raw_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPMJsVcPD40H",
        "outputId": "547af658-023f-4ba3-aacc-6f7ad78b50c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LowerCase:  i am learning python,programming. python is greatest language....!!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2\n",
        "tokens = word_tokenize(raw_txt)\n",
        "print(\"Token:\",tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR-UstxaEZFS",
        "outputId": "e0cd2535-b06f-4640-f103-a84e395c36b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: ['i', 'am', 'learning', 'python', ',', 'programming', '.', 'python', 'is', 'greatest', 'language', '....', '!', '!', '!', '!', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step -3:Remove stopwords\n",
        "english_stopwords= stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "kuVi8-9QFoZg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens = []\n",
        "for word in tokens:\n",
        "  if word not in english_stopwords:\n",
        "    filtered_tokens.append(word)\n",
        "print(\"Filtered Tokens: \",filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0nJL4sfGRtG",
        "outputId": "6b571f3a-f152-4c09-fc36-1535e0b1965f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Tokens:  ['learning', 'python', ',', 'programming', '.', 'python', 'greatest', 'language', '....', '!', '!', '!', '!', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step -4 Remove punctuation\n",
        "import string\n",
        "punctuation = string.punctuation\n",
        "print(\"Punctuation Available : \",punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ4au-gsGy3j",
        "outputId": "3a61de4c-7526-470f-bff1-ccb616aaedc3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation Available :  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_tokens = [word for word in filtered_tokens if word not in punctuation]\n",
        "print(\"After removing punctuations: \",clean_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWtaVozOHGZa",
        "outputId": "1a501e1d-31a4-4fab-b7e2-00d71a361436"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After removing punctuations:  ['learning', 'python', 'programming', 'python', 'greatest', 'language', '....']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem = PorterStemmer()\n",
        "# stem.stem(\"played\")\n",
        "# stem.stem(\"flying\")\n",
        "stem.stem(\"gretest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gWA8zmyXHodc",
        "outputId": "0e1b3273-2c34-4b78-8fac-9ba0b41505e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gretest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wnet = WordNetLemmatizer()\n",
        "#wnet.lemmatize(\"playing\",\"v\")\n",
        "wnet.lemmatize(\"flying\",\"v\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rQd6xi5SIPIC",
        "outputId": "56e362a7-60eb-4269-f378-a093eb5c1969"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fly'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words =[]\n",
        "for word in clean_tokens:\n",
        "  lemmatized_words.append(wnet.lemmatize(word,\"v\"))\n",
        "print(\"After lemmatization: \",lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvEsLTV1IxR8",
        "outputId": "fc60905f-5886-4343-94a1-11dadbc614f3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After lemmatization:  ['learn', 'python', 'program', 'python', 'greatest', 'language', '....']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_tokens = []\n",
        "for word in lemmatized_words:\n",
        "  if word.isalpha():\n",
        "    final_tokens.append(word)\n",
        "print(\"Final Tokens: \",final_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yho5J-AlJaOM",
        "outputId": "a5abc896-a56e-45b9-e6b7-23a647b6876f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Tokens:  ['learn', 'python', 'program', 'python', 'greatest', 'language']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_txt = \" \".join(final_tokens)\n",
        "print(\"Processed Text :\",cleaned_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBdjAF0iJ5M0",
        "outputId": "94a33807-2933-443e-9784-bae4862ddbcc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Text : learn python program python greatest language\n"
          ]
        }
      ]
    }
  ]
}